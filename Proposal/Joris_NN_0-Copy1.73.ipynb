{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the files to be shared among all notebooks \n",
    "import utils\n",
    "import preprocessing\n",
    "import data_visualization\n",
    "import feature_engineering\n",
    "from ML_algorithms import *\n",
    "import pandas as pd\n",
    "from seaborn import countplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing.encode_education(df)\n",
    "df = preprocessing.one_hot_encoding(df,columns = [\"Marital_Status\"])\n",
    "df = preprocessing.encode_days_as_costumer(df)\n",
    "df = feature_engineering.drop_useless_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing.impute_income_KNN(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Kidhome\",\"Teenhome\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>...</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Response</th>\n",
       "      <th>Marital_Status_Absurd</th>\n",
       "      <th>Marital_Status_Alone</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Together</th>\n",
       "      <th>Marital_Status_Widow</th>\n",
       "      <th>Marital_Status_YOLO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1957</td>\n",
       "      <td>2</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>663</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>88</td>\n",
       "      <td>546</td>\n",
       "      <td>172</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1954</td>\n",
       "      <td>2</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>113</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1965</td>\n",
       "      <td>2</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>312</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>49</td>\n",
       "      <td>127</td>\n",
       "      <td>111</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984</td>\n",
       "      <td>2</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>139</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981</td>\n",
       "      <td>4</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>161</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>43</td>\n",
       "      <td>118</td>\n",
       "      <td>46</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_Birth  Education   Income  Dt_Customer  Recency  MntWines  MntFruits  \\\n",
       "0        1957          2  58138.0          663       58       635         88   \n",
       "1        1954          2  46344.0          113       38        11          1   \n",
       "2        1965          2  71613.0          312       26       426         49   \n",
       "3        1984          2  26646.0          139       26        11          4   \n",
       "4        1981          4  58293.0          161       94       173         43   \n",
       "\n",
       "   MntMeatProducts  MntFishProducts  MntSweetProducts  ...  Complain  \\\n",
       "0              546              172                88  ...         0   \n",
       "1                6                2                 1  ...         0   \n",
       "2              127              111                21  ...         0   \n",
       "3               20               10                 3  ...         0   \n",
       "4              118               46                27  ...         0   \n",
       "\n",
       "   Response  Marital_Status_Absurd  Marital_Status_Alone  \\\n",
       "0         1                      0                     0   \n",
       "1         0                      0                     0   \n",
       "2         0                      0                     0   \n",
       "3         0                      0                     0   \n",
       "4         0                      0                     0   \n",
       "\n",
       "   Marital_Status_Divorced  Marital_Status_Married  Marital_Status_Single  \\\n",
       "0                        0                       0                      1   \n",
       "1                        0                       0                      1   \n",
       "2                        0                       0                      0   \n",
       "3                        0                       0                      0   \n",
       "4                        0                       1                      0   \n",
       "\n",
       "   Marital_Status_Together  Marital_Status_Widow  Marital_Status_YOLO  \n",
       "0                        0                     0                    0  \n",
       "1                        0                     0                    0  \n",
       "2                        1                     0                    0  \n",
       "3                        1                     0                    0  \n",
       "4                        0                     0                    0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all columns\n",
    "columns = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove target feature Response from the list\n",
    "columns.remove(\"Response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5f2ba8d198>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# very imbalanced dataset\n",
    "countplot(x=\"Response\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# transform the df to X_f using the exact ratio of 0 and 1: 17%\n",
    "X_f = preprocessing.centroid_undersampling(X=df, f=0.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f42f9958710>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now the dataset is balanced\n",
    "countplot(x=\"Response\", data=X_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the train, test split\n",
    "X_train, X_test, y_train, y_test = utils.data_split(X_f, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(6, activation=\"relu\", input_dim=30))\n",
    "model.add(layers.Dense(6, activation=\"relu\"))\n",
    "model.add(layers.Dense(6, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "526/526 [==============================] - 0s 806us/step - loss: 0.6878 - acc: 0.5989\n",
      "Epoch 2/100\n",
      "526/526 [==============================] - 0s 44us/step - loss: 0.6853 - acc: 0.5970\n",
      "Epoch 3/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.6823 - acc: 0.6160\n",
      "Epoch 4/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.6784 - acc: 0.6255\n",
      "Epoch 5/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.6740 - acc: 0.6312\n",
      "Epoch 6/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.6687 - acc: 0.6445\n",
      "Epoch 7/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.6633 - acc: 0.6540\n",
      "Epoch 8/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.6576 - acc: 0.6692\n",
      "Epoch 9/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.6508 - acc: 0.6787\n",
      "Epoch 10/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.6432 - acc: 0.6901\n",
      "Epoch 11/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.6350 - acc: 0.7053\n",
      "Epoch 12/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.6259 - acc: 0.7167\n",
      "Epoch 13/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.6156 - acc: 0.7167\n",
      "Epoch 14/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.6053 - acc: 0.7395\n",
      "Epoch 15/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.5939 - acc: 0.7395\n",
      "Epoch 16/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.5831 - acc: 0.7567\n",
      "Epoch 17/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.5731 - acc: 0.7452\n",
      "Epoch 18/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.5616 - acc: 0.7433\n",
      "Epoch 19/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.5492 - acc: 0.7529\n",
      "Epoch 20/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.5373 - acc: 0.7529\n",
      "Epoch 21/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.5250 - acc: 0.7548\n",
      "Epoch 22/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.5134 - acc: 0.7567\n",
      "Epoch 23/100\n",
      "526/526 [==============================] - 0s 40us/step - loss: 0.5038 - acc: 0.7624\n",
      "Epoch 24/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4951 - acc: 0.7624\n",
      "Epoch 25/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.4867 - acc: 0.7662\n",
      "Epoch 26/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4784 - acc: 0.7643\n",
      "Epoch 27/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.4712 - acc: 0.7795\n",
      "Epoch 28/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.4657 - acc: 0.7757\n",
      "Epoch 29/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.4586 - acc: 0.7814\n",
      "Epoch 30/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.4522 - acc: 0.7852\n",
      "Epoch 31/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.4474 - acc: 0.7890\n",
      "Epoch 32/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.4427 - acc: 0.7871\n",
      "Epoch 33/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.4395 - acc: 0.7966\n",
      "Epoch 34/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4354 - acc: 0.7985\n",
      "Epoch 35/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.4319 - acc: 0.7909\n",
      "Epoch 36/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.4288 - acc: 0.7928\n",
      "Epoch 37/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.4251 - acc: 0.7985\n",
      "Epoch 38/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.4240 - acc: 0.7985\n",
      "Epoch 39/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.4197 - acc: 0.8042\n",
      "Epoch 40/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.4180 - acc: 0.7909\n",
      "Epoch 41/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4158 - acc: 0.7871\n",
      "Epoch 42/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4154 - acc: 0.8023\n",
      "Epoch 43/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4117 - acc: 0.8042\n",
      "Epoch 44/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.4110 - acc: 0.8061\n",
      "Epoch 45/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.4083 - acc: 0.8137\n",
      "Epoch 46/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.4076 - acc: 0.8042\n",
      "Epoch 47/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.4065 - acc: 0.8080\n",
      "Epoch 48/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.4040 - acc: 0.8137\n",
      "Epoch 49/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.4020 - acc: 0.8156\n",
      "Epoch 50/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.4041 - acc: 0.8004\n",
      "Epoch 51/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4029 - acc: 0.8080\n",
      "Epoch 52/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4004 - acc: 0.8099\n",
      "Epoch 53/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3989 - acc: 0.8099\n",
      "Epoch 54/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.3984 - acc: 0.8080\n",
      "Epoch 55/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3980 - acc: 0.8099\n",
      "Epoch 56/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.3966 - acc: 0.8080\n",
      "Epoch 57/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3973 - acc: 0.8099\n",
      "Epoch 58/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3943 - acc: 0.8080\n",
      "Epoch 59/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.3955 - acc: 0.8137\n",
      "Epoch 60/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3949 - acc: 0.8080\n",
      "Epoch 61/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3932 - acc: 0.8099\n",
      "Epoch 62/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3921 - acc: 0.8156\n",
      "Epoch 63/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3930 - acc: 0.8042\n",
      "Epoch 64/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3926 - acc: 0.8156\n",
      "Epoch 65/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3893 - acc: 0.8137\n",
      "Epoch 66/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.3899 - acc: 0.8137\n",
      "Epoch 67/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.3891 - acc: 0.8137\n",
      "Epoch 68/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3884 - acc: 0.8099\n",
      "Epoch 69/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3877 - acc: 0.8156\n",
      "Epoch 70/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3890 - acc: 0.8118\n",
      "Epoch 71/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.3871 - acc: 0.8118\n",
      "Epoch 72/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3864 - acc: 0.8099\n",
      "Epoch 73/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.3858 - acc: 0.8099\n",
      "Epoch 74/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3867 - acc: 0.8118\n",
      "Epoch 75/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3842 - acc: 0.8156\n",
      "Epoch 76/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3848 - acc: 0.8080\n",
      "Epoch 77/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3831 - acc: 0.8118\n",
      "Epoch 78/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3848 - acc: 0.8118\n",
      "Epoch 79/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3824 - acc: 0.8118\n",
      "Epoch 80/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3818 - acc: 0.8137\n",
      "Epoch 81/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3815 - acc: 0.8194\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526/526 [==============================] - 0s 35us/step - loss: 0.3810 - acc: 0.8137\n",
      "Epoch 83/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3807 - acc: 0.8118\n",
      "Epoch 84/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3798 - acc: 0.8194\n",
      "Epoch 85/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3798 - acc: 0.8137\n",
      "Epoch 86/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3786 - acc: 0.8061\n",
      "Epoch 87/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3796 - acc: 0.8175\n",
      "Epoch 88/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3788 - acc: 0.8137\n",
      "Epoch 89/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3777 - acc: 0.8156\n",
      "Epoch 90/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3782 - acc: 0.8156\n",
      "Epoch 91/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3752 - acc: 0.8137\n",
      "Epoch 92/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3771 - acc: 0.8213\n",
      "Epoch 93/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3747 - acc: 0.8137\n",
      "Epoch 94/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.3751 - acc: 0.8137\n",
      "Epoch 95/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3743 - acc: 0.8194\n",
      "Epoch 96/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3736 - acc: 0.8194\n",
      "Epoch 97/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3726 - acc: 0.8194\n",
      "Epoch 98/100\n",
      "526/526 [==============================] - 0s 40us/step - loss: 0.3744 - acc: 0.8175\n",
      "Epoch 99/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3724 - acc: 0.8118\n",
      "Epoch 100/100\n",
      "526/526 [==============================] - 0s 41us/step - loss: 0.3717 - acc: 0.8156\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100)\n",
    "y_predicted = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 475us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4372568004059069, 0.8181818181818182]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in y_predicted:\n",
    "    if i < 0.5:\n",
    "        i=0\n",
    "        y_pred.append(i)\n",
    "    else:\n",
    "        i=1\n",
    "        y_pred.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.75362319 0.24637681]\n",
      " [0.11111111 0.88888889]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = utils.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "data_visualization.plot_confusion_matrix(conf_matrix, ['not bought', 'bought'], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.82\n",
      "Area under the curve 0.82\n",
      "Precision 0.89\n",
      "Recall 0.77\n",
      "Profit Share 0.73\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy {:1.2f}\".format(utils.calculate_accuracy(y_pred, y_test)))\n",
    "print(\"Area under the curve {:1.2f}\".format(utils.calculate_auc(y_pred, y_test)))\n",
    "print(\"Precision {:1.2f}\".format(utils.calculate_precision_score(y_pred, y_test)))\n",
    "print(\"Recall {:1.2f}\".format(utils.calculate_recall_score(y_pred, y_test)))\n",
    "print(\"Profit Share {:1.2f}\".format(utils.profit_share(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "seeds=[0,1,2,3,4]\n",
    "average_profit_share = 0\n",
    "sum_profit_share = 0\n",
    "\n",
    "for seed in range(5):\n",
    "    \n",
    "    x = utils.profit_share(y_pred, y_test)\n",
    "    sum_profit_share = sum_profit_share + x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/2_Semester/Machine Learning/MLProjects/Proposal/preprocessing.py:236: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_label[\"distance\"] = 0\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/jovyan/work/2_Semester/Machine Learning/MLProjects/Proposal/preprocessing.py:246: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_label.sort_values(by=['distance'], ascending=False, inplace=True)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "526/526 [==============================] - 0s 507us/step - loss: 0.6885 - acc: 0.5057\n",
      "Epoch 2/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.6831 - acc: 0.5171\n",
      "Epoch 3/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.6786 - acc: 0.5209\n",
      "Epoch 4/100\n",
      "526/526 [==============================] - 0s 44us/step - loss: 0.6740 - acc: 0.5304\n",
      "Epoch 5/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.6694 - acc: 0.5342\n",
      "Epoch 6/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.6635 - acc: 0.5513\n",
      "Epoch 7/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.6576 - acc: 0.5817\n",
      "Epoch 8/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.6508 - acc: 0.6065\n",
      "Epoch 9/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.6433 - acc: 0.6179\n",
      "Epoch 10/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.6362 - acc: 0.6274\n",
      "Epoch 11/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.6290 - acc: 0.6768\n",
      "Epoch 12/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.6208 - acc: 0.7034\n",
      "Epoch 13/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.6129 - acc: 0.7167\n",
      "Epoch 14/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.6059 - acc: 0.7376\n",
      "Epoch 15/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.5979 - acc: 0.7529\n",
      "Epoch 16/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.5899 - acc: 0.7624\n",
      "Epoch 17/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.5818 - acc: 0.7643\n",
      "Epoch 18/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.5744 - acc: 0.7814\n",
      "Epoch 19/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.5670 - acc: 0.7833\n",
      "Epoch 20/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.5599 - acc: 0.7871\n",
      "Epoch 21/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.5525 - acc: 0.7909\n",
      "Epoch 22/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.5450 - acc: 0.7871\n",
      "Epoch 23/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.5380 - acc: 0.7947\n",
      "Epoch 24/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.5300 - acc: 0.8004\n",
      "Epoch 25/100\n",
      "526/526 [==============================] - 0s 40us/step - loss: 0.5227 - acc: 0.8042\n",
      "Epoch 26/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.5147 - acc: 0.7966\n",
      "Epoch 27/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.5072 - acc: 0.8042\n",
      "Epoch 28/100\n",
      "526/526 [==============================] - 0s 41us/step - loss: 0.4997 - acc: 0.8042\n",
      "Epoch 29/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.4919 - acc: 0.8080\n",
      "Epoch 30/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.4847 - acc: 0.8080\n",
      "Epoch 31/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.4775 - acc: 0.8099\n",
      "Epoch 32/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.4707 - acc: 0.8023\n",
      "Epoch 33/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.4640 - acc: 0.8061\n",
      "Epoch 34/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.4593 - acc: 0.8118\n",
      "Epoch 35/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.4532 - acc: 0.8099\n",
      "Epoch 36/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.4477 - acc: 0.8099\n",
      "Epoch 37/100\n",
      "526/526 [==============================] - 0s 40us/step - loss: 0.4414 - acc: 0.8137\n",
      "Epoch 38/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.4374 - acc: 0.8137\n",
      "Epoch 39/100\n",
      "526/526 [==============================] - 0s 42us/step - loss: 0.4318 - acc: 0.8251\n",
      "Epoch 40/100\n",
      "526/526 [==============================] - 0s 45us/step - loss: 0.4264 - acc: 0.8194\n",
      "Epoch 41/100\n",
      "526/526 [==============================] - 0s 47us/step - loss: 0.4239 - acc: 0.8270\n",
      "Epoch 42/100\n",
      "526/526 [==============================] - 0s 47us/step - loss: 0.4214 - acc: 0.8289\n",
      "Epoch 43/100\n",
      "526/526 [==============================] - 0s 46us/step - loss: 0.4151 - acc: 0.8289\n",
      "Epoch 44/100\n",
      "526/526 [==============================] - 0s 40us/step - loss: 0.4138 - acc: 0.8232\n",
      "Epoch 45/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.4108 - acc: 0.8270\n",
      "Epoch 46/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.4077 - acc: 0.8365\n",
      "Epoch 47/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.4051 - acc: 0.8403\n",
      "Epoch 48/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.4033 - acc: 0.8384\n",
      "Epoch 49/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.4000 - acc: 0.8346\n",
      "Epoch 50/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.3978 - acc: 0.8403\n",
      "Epoch 51/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3953 - acc: 0.8384\n",
      "Epoch 52/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3931 - acc: 0.8422\n",
      "Epoch 53/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3911 - acc: 0.8479\n",
      "Epoch 54/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3891 - acc: 0.8403\n",
      "Epoch 55/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3862 - acc: 0.8403\n",
      "Epoch 56/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3858 - acc: 0.8422\n",
      "Epoch 57/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3843 - acc: 0.8441\n",
      "Epoch 58/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3833 - acc: 0.8460\n",
      "Epoch 59/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3822 - acc: 0.8384\n",
      "Epoch 60/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3796 - acc: 0.8479\n",
      "Epoch 61/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.3806 - acc: 0.8441\n",
      "Epoch 62/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.3791 - acc: 0.8422\n",
      "Epoch 63/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3760 - acc: 0.8460\n",
      "Epoch 64/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3749 - acc: 0.8460\n",
      "Epoch 65/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3731 - acc: 0.8384\n",
      "Epoch 66/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3729 - acc: 0.8517\n",
      "Epoch 67/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3715 - acc: 0.8422\n",
      "Epoch 68/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3715 - acc: 0.8479\n",
      "Epoch 69/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.3706 - acc: 0.8460\n",
      "Epoch 70/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3678 - acc: 0.8460\n",
      "Epoch 71/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.3680 - acc: 0.8517\n",
      "Epoch 72/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.3675 - acc: 0.8498\n",
      "Epoch 73/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.3662 - acc: 0.8422\n",
      "Epoch 74/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3657 - acc: 0.8460\n",
      "Epoch 75/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3644 - acc: 0.8441\n",
      "Epoch 76/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3627 - acc: 0.8479\n",
      "Epoch 77/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3624 - acc: 0.8498\n",
      "Epoch 78/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3630 - acc: 0.8498\n",
      "Epoch 79/100\n",
      "526/526 [==============================] - 0s 40us/step - loss: 0.3607 - acc: 0.8479\n",
      "Epoch 80/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3604 - acc: 0.8498\n",
      "Epoch 81/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3589 - acc: 0.8441\n",
      "Epoch 82/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3586 - acc: 0.8498\n",
      "Epoch 83/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3579 - acc: 0.8441\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526/526 [==============================] - 0s 34us/step - loss: 0.3564 - acc: 0.8498\n",
      "Epoch 85/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3570 - acc: 0.8479\n",
      "Epoch 86/100\n",
      "526/526 [==============================] - 0s 41us/step - loss: 0.3549 - acc: 0.8460\n",
      "Epoch 87/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3565 - acc: 0.8479\n",
      "Epoch 88/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3536 - acc: 0.8536\n",
      "Epoch 89/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3530 - acc: 0.8479\n",
      "Epoch 90/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3551 - acc: 0.8479\n",
      "Epoch 91/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3515 - acc: 0.8498\n",
      "Epoch 92/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3524 - acc: 0.8498\n",
      "Epoch 93/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3520 - acc: 0.8536\n",
      "Epoch 94/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3503 - acc: 0.8460\n",
      "Epoch 95/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3495 - acc: 0.8536\n",
      "Epoch 96/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3498 - acc: 0.8422\n",
      "Epoch 97/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.3485 - acc: 0.8498\n",
      "Epoch 98/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3478 - acc: 0.8498\n",
      "Epoch 99/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3472 - acc: 0.8517\n",
      "Epoch 100/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3482 - acc: 0.8555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/2_Semester/Machine Learning/MLProjects/Proposal/preprocessing.py:236: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_label[\"distance\"] = 0\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/jovyan/work/2_Semester/Machine Learning/MLProjects/Proposal/preprocessing.py:246: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_label.sort_values(by=['distance'], ascending=False, inplace=True)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "526/526 [==============================] - 0s 565us/step - loss: 0.6802 - acc: 0.5837\n",
      "Epoch 2/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.6735 - acc: 0.5875\n",
      "Epoch 3/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.6675 - acc: 0.6331\n",
      "Epoch 4/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.6609 - acc: 0.6540\n",
      "Epoch 5/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.6539 - acc: 0.6730\n",
      "Epoch 6/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.6460 - acc: 0.6787\n",
      "Epoch 7/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.6382 - acc: 0.7148\n",
      "Epoch 8/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.6301 - acc: 0.7148\n",
      "Epoch 9/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.6217 - acc: 0.7376\n",
      "Epoch 10/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.6127 - acc: 0.7471\n",
      "Epoch 11/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.6034 - acc: 0.7395\n",
      "Epoch 12/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.5954 - acc: 0.7681\n",
      "Epoch 13/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.5857 - acc: 0.7738\n",
      "Epoch 14/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.5770 - acc: 0.7776\n",
      "Epoch 15/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.5688 - acc: 0.7757\n",
      "Epoch 16/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.5599 - acc: 0.7871\n",
      "Epoch 17/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.5525 - acc: 0.7909\n",
      "Epoch 18/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.5448 - acc: 0.7947\n",
      "Epoch 19/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.5386 - acc: 0.7985\n",
      "Epoch 20/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.5319 - acc: 0.7909\n",
      "Epoch 21/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.5249 - acc: 0.7928\n",
      "Epoch 22/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.5204 - acc: 0.7966\n",
      "Epoch 23/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.5140 - acc: 0.8004\n",
      "Epoch 24/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.5072 - acc: 0.8023\n",
      "Epoch 25/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.5022 - acc: 0.8004\n",
      "Epoch 26/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.4968 - acc: 0.8023\n",
      "Epoch 27/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.4923 - acc: 0.8080\n",
      "Epoch 28/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.4867 - acc: 0.8099\n",
      "Epoch 29/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4836 - acc: 0.8042\n",
      "Epoch 30/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4784 - acc: 0.8061\n",
      "Epoch 31/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.4735 - acc: 0.8137\n",
      "Epoch 32/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4701 - acc: 0.8118\n",
      "Epoch 33/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.4660 - acc: 0.8156\n",
      "Epoch 34/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.4627 - acc: 0.8137\n",
      "Epoch 35/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.4594 - acc: 0.8156\n",
      "Epoch 36/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4558 - acc: 0.8137\n",
      "Epoch 37/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4525 - acc: 0.8137\n",
      "Epoch 38/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4500 - acc: 0.8118\n",
      "Epoch 39/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.4466 - acc: 0.8175\n",
      "Epoch 40/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.4443 - acc: 0.8175\n",
      "Epoch 41/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.4405 - acc: 0.8213\n",
      "Epoch 42/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.4381 - acc: 0.8251\n",
      "Epoch 43/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.4363 - acc: 0.8175\n",
      "Epoch 44/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.4341 - acc: 0.8156\n",
      "Epoch 45/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4301 - acc: 0.8251\n",
      "Epoch 46/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.4289 - acc: 0.8232\n",
      "Epoch 47/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4266 - acc: 0.8213\n",
      "Epoch 48/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4251 - acc: 0.8213\n",
      "Epoch 49/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4224 - acc: 0.8232\n",
      "Epoch 50/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.4213 - acc: 0.8270\n",
      "Epoch 51/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.4184 - acc: 0.8251\n",
      "Epoch 52/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.4180 - acc: 0.8232\n",
      "Epoch 53/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.4147 - acc: 0.8270\n",
      "Epoch 54/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.4127 - acc: 0.8213\n",
      "Epoch 55/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.4115 - acc: 0.8251\n",
      "Epoch 56/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.4101 - acc: 0.8289\n",
      "Epoch 57/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4080 - acc: 0.8213\n",
      "Epoch 58/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4097 - acc: 0.8270\n",
      "Epoch 59/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.4072 - acc: 0.8327\n",
      "Epoch 60/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.4056 - acc: 0.8270\n",
      "Epoch 61/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4037 - acc: 0.8251\n",
      "Epoch 62/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.4058 - acc: 0.8213\n",
      "Epoch 63/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.4004 - acc: 0.8232\n",
      "Epoch 64/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.4007 - acc: 0.8346\n",
      "Epoch 65/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4006 - acc: 0.8289\n",
      "Epoch 66/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.3970 - acc: 0.8270\n",
      "Epoch 67/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3969 - acc: 0.8384\n",
      "Epoch 68/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3970 - acc: 0.8289\n",
      "Epoch 69/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.3953 - acc: 0.8308\n",
      "Epoch 70/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.3931 - acc: 0.8365\n",
      "Epoch 71/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3920 - acc: 0.8308\n",
      "Epoch 72/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3916 - acc: 0.8327\n",
      "Epoch 73/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.3901 - acc: 0.8346\n",
      "Epoch 74/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3901 - acc: 0.8346\n",
      "Epoch 75/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3884 - acc: 0.8365\n",
      "Epoch 76/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3867 - acc: 0.8365\n",
      "Epoch 77/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3882 - acc: 0.8403\n",
      "Epoch 78/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3842 - acc: 0.8422\n",
      "Epoch 79/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3841 - acc: 0.8422\n",
      "Epoch 80/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3811 - acc: 0.8403\n",
      "Epoch 81/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3809 - acc: 0.8327\n",
      "Epoch 82/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3810 - acc: 0.8384\n",
      "Epoch 83/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3806 - acc: 0.8422\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526/526 [==============================] - 0s 35us/step - loss: 0.3777 - acc: 0.8384\n",
      "Epoch 85/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3772 - acc: 0.8403\n",
      "Epoch 86/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3764 - acc: 0.8346\n",
      "Epoch 87/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3781 - acc: 0.8384\n",
      "Epoch 88/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3756 - acc: 0.8422\n",
      "Epoch 89/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3747 - acc: 0.8384\n",
      "Epoch 90/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3715 - acc: 0.8422\n",
      "Epoch 91/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3721 - acc: 0.8327\n",
      "Epoch 92/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3718 - acc: 0.8384\n",
      "Epoch 93/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3703 - acc: 0.8384\n",
      "Epoch 94/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3701 - acc: 0.8460\n",
      "Epoch 95/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3683 - acc: 0.8403\n",
      "Epoch 96/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3654 - acc: 0.8479\n",
      "Epoch 97/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.3683 - acc: 0.8460\n",
      "Epoch 98/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3660 - acc: 0.8346\n",
      "Epoch 99/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3631 - acc: 0.8460\n",
      "Epoch 100/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3654 - acc: 0.8498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/2_Semester/Machine Learning/MLProjects/Proposal/preprocessing.py:236: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_label[\"distance\"] = 0\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/jovyan/work/2_Semester/Machine Learning/MLProjects/Proposal/preprocessing.py:246: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_label.sort_values(by=['distance'], ascending=False, inplace=True)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "526/526 [==============================] - 0s 614us/step - loss: 0.7004 - acc: 0.5076\n",
      "Epoch 2/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6963 - acc: 0.5209\n",
      "Epoch 3/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.6940 - acc: 0.5247\n",
      "Epoch 4/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6924 - acc: 0.5228\n",
      "Epoch 5/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.6907 - acc: 0.5342\n",
      "Epoch 6/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.6892 - acc: 0.5418\n",
      "Epoch 7/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.6874 - acc: 0.5589\n",
      "Epoch 8/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6856 - acc: 0.5817\n",
      "Epoch 9/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6832 - acc: 0.5951\n",
      "Epoch 10/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6806 - acc: 0.6141\n",
      "Epoch 11/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6777 - acc: 0.6122\n",
      "Epoch 12/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.6744 - acc: 0.6236\n",
      "Epoch 13/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.6709 - acc: 0.6388\n",
      "Epoch 14/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6667 - acc: 0.6388\n",
      "Epoch 15/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6624 - acc: 0.6445\n",
      "Epoch 16/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6574 - acc: 0.6426\n",
      "Epoch 17/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6520 - acc: 0.6559\n",
      "Epoch 18/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.6461 - acc: 0.6749\n",
      "Epoch 19/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6397 - acc: 0.6787\n",
      "Epoch 20/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6331 - acc: 0.6863\n",
      "Epoch 21/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6263 - acc: 0.7015\n",
      "Epoch 22/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6185 - acc: 0.7034\n",
      "Epoch 23/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.6107 - acc: 0.7072\n",
      "Epoch 24/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6028 - acc: 0.7300\n",
      "Epoch 25/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.5947 - acc: 0.7319\n",
      "Epoch 26/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.5861 - acc: 0.7395\n",
      "Epoch 27/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.5766 - acc: 0.7510\n",
      "Epoch 28/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.5678 - acc: 0.7662\n",
      "Epoch 29/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.5584 - acc: 0.7624\n",
      "Epoch 30/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.5491 - acc: 0.7928\n",
      "Epoch 31/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.5401 - acc: 0.7833\n",
      "Epoch 32/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.5302 - acc: 0.7909\n",
      "Epoch 33/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.5214 - acc: 0.8042\n",
      "Epoch 34/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.5128 - acc: 0.8023\n",
      "Epoch 35/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.5045 - acc: 0.8099\n",
      "Epoch 36/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4975 - acc: 0.8042\n",
      "Epoch 37/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.4897 - acc: 0.8042\n",
      "Epoch 38/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.4825 - acc: 0.8232\n",
      "Epoch 39/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.4752 - acc: 0.8156\n",
      "Epoch 40/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.4675 - acc: 0.8194\n",
      "Epoch 41/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.4603 - acc: 0.8289\n",
      "Epoch 42/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.4543 - acc: 0.8346\n",
      "Epoch 43/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.4485 - acc: 0.8289\n",
      "Epoch 44/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4429 - acc: 0.8346\n",
      "Epoch 45/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4378 - acc: 0.8308\n",
      "Epoch 46/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.4330 - acc: 0.8327\n",
      "Epoch 47/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.4284 - acc: 0.8327\n",
      "Epoch 48/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.4231 - acc: 0.8365\n",
      "Epoch 49/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4189 - acc: 0.8384\n",
      "Epoch 50/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4130 - acc: 0.8270\n",
      "Epoch 51/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4097 - acc: 0.8365\n",
      "Epoch 52/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.4051 - acc: 0.8384\n",
      "Epoch 53/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.4016 - acc: 0.8422\n",
      "Epoch 54/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3978 - acc: 0.8403\n",
      "Epoch 55/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3945 - acc: 0.8384\n",
      "Epoch 56/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3920 - acc: 0.8365\n",
      "Epoch 57/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3885 - acc: 0.8422\n",
      "Epoch 58/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3849 - acc: 0.8384\n",
      "Epoch 59/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3825 - acc: 0.8403\n",
      "Epoch 60/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3786 - acc: 0.8403\n",
      "Epoch 61/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3775 - acc: 0.8403\n",
      "Epoch 62/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.3742 - acc: 0.8403\n",
      "Epoch 63/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3722 - acc: 0.8422\n",
      "Epoch 64/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3697 - acc: 0.8403\n",
      "Epoch 65/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3681 - acc: 0.8384\n",
      "Epoch 66/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3656 - acc: 0.8441\n",
      "Epoch 67/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3644 - acc: 0.8403\n",
      "Epoch 68/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3633 - acc: 0.8441\n",
      "Epoch 69/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3605 - acc: 0.8460\n",
      "Epoch 70/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3602 - acc: 0.8460\n",
      "Epoch 71/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3578 - acc: 0.8479\n",
      "Epoch 72/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3556 - acc: 0.8441\n",
      "Epoch 73/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3545 - acc: 0.8460\n",
      "Epoch 74/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3537 - acc: 0.8479\n",
      "Epoch 75/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3511 - acc: 0.8441\n",
      "Epoch 76/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3505 - acc: 0.8498\n",
      "Epoch 77/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3481 - acc: 0.8555\n",
      "Epoch 78/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3483 - acc: 0.8517\n",
      "Epoch 79/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3461 - acc: 0.8517\n",
      "Epoch 80/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3436 - acc: 0.8593\n",
      "Epoch 81/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3426 - acc: 0.8574\n",
      "Epoch 82/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3425 - acc: 0.8517\n",
      "Epoch 83/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3389 - acc: 0.8612\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526/526 [==============================] - 0s 28us/step - loss: 0.3407 - acc: 0.8498\n",
      "Epoch 85/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3372 - acc: 0.8536\n",
      "Epoch 86/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3398 - acc: 0.8555\n",
      "Epoch 87/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3373 - acc: 0.8612\n",
      "Epoch 88/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3360 - acc: 0.8536\n",
      "Epoch 89/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.3344 - acc: 0.8612\n",
      "Epoch 90/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3340 - acc: 0.8612\n",
      "Epoch 91/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3313 - acc: 0.8593\n",
      "Epoch 92/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3321 - acc: 0.8574\n",
      "Epoch 93/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3296 - acc: 0.8612\n",
      "Epoch 94/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3295 - acc: 0.8574\n",
      "Epoch 95/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3291 - acc: 0.8593\n",
      "Epoch 96/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3276 - acc: 0.8517\n",
      "Epoch 97/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3266 - acc: 0.8593\n",
      "Epoch 98/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3250 - acc: 0.8688\n",
      "Epoch 99/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3234 - acc: 0.8650\n",
      "Epoch 100/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3227 - acc: 0.8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/2_Semester/Machine Learning/MLProjects/Proposal/preprocessing.py:236: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_label[\"distance\"] = 0\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/jovyan/work/2_Semester/Machine Learning/MLProjects/Proposal/preprocessing.py:246: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_label.sort_values(by=['distance'], ascending=False, inplace=True)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "526/526 [==============================] - 0s 763us/step - loss: 0.6922 - acc: 0.4943\n",
      "Epoch 2/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.6816 - acc: 0.5323\n",
      "Epoch 3/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.6760 - acc: 0.5817\n",
      "Epoch 4/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.6709 - acc: 0.6141\n",
      "Epoch 5/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.6645 - acc: 0.6312\n",
      "Epoch 6/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.6559 - acc: 0.6673\n",
      "Epoch 7/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.6468 - acc: 0.6844\n",
      "Epoch 8/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.6374 - acc: 0.6977\n",
      "Epoch 9/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.6276 - acc: 0.7148\n",
      "Epoch 10/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.6164 - acc: 0.7281\n",
      "Epoch 11/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.6052 - acc: 0.7224\n",
      "Epoch 12/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.5935 - acc: 0.7357\n",
      "Epoch 13/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.5815 - acc: 0.7395\n",
      "Epoch 14/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.5717 - acc: 0.7490\n",
      "Epoch 15/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.5611 - acc: 0.7586\n",
      "Epoch 16/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.5508 - acc: 0.7643\n",
      "Epoch 17/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.5399 - acc: 0.7681\n",
      "Epoch 18/100\n",
      "526/526 [==============================] - 0s 43us/step - loss: 0.5295 - acc: 0.7795\n",
      "Epoch 19/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.5194 - acc: 0.7814\n",
      "Epoch 20/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.5101 - acc: 0.7852\n",
      "Epoch 21/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.5002 - acc: 0.7871\n",
      "Epoch 22/100\n",
      "526/526 [==============================] - 0s 33us/step - loss: 0.4920 - acc: 0.7890\n",
      "Epoch 23/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4834 - acc: 0.7966\n",
      "Epoch 24/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.4765 - acc: 0.7966\n",
      "Epoch 25/100\n",
      "526/526 [==============================] - 0s 40us/step - loss: 0.4685 - acc: 0.8042\n",
      "Epoch 26/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.4618 - acc: 0.8023\n",
      "Epoch 27/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.4554 - acc: 0.8099\n",
      "Epoch 28/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.4476 - acc: 0.8232\n",
      "Epoch 29/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.4421 - acc: 0.8213\n",
      "Epoch 30/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.4359 - acc: 0.8232\n",
      "Epoch 31/100\n",
      "526/526 [==============================] - 0s 42us/step - loss: 0.4309 - acc: 0.8232\n",
      "Epoch 32/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.4257 - acc: 0.8346\n",
      "Epoch 33/100\n",
      "526/526 [==============================] - 0s 43us/step - loss: 0.4219 - acc: 0.8308\n",
      "Epoch 34/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.4175 - acc: 0.8308\n",
      "Epoch 35/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.4144 - acc: 0.8346\n",
      "Epoch 36/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.4096 - acc: 0.8308\n",
      "Epoch 37/100\n",
      "526/526 [==============================] - 0s 40us/step - loss: 0.4063 - acc: 0.8384\n",
      "Epoch 38/100\n",
      "526/526 [==============================] - 0s 40us/step - loss: 0.4033 - acc: 0.8327\n",
      "Epoch 39/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.3985 - acc: 0.8346\n",
      "Epoch 40/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.3958 - acc: 0.8365\n",
      "Epoch 41/100\n",
      "526/526 [==============================] - 0s 40us/step - loss: 0.3918 - acc: 0.8346\n",
      "Epoch 42/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.3879 - acc: 0.8403\n",
      "Epoch 43/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3862 - acc: 0.8327\n",
      "Epoch 44/100\n",
      "526/526 [==============================] - 0s 41us/step - loss: 0.3830 - acc: 0.8460\n",
      "Epoch 45/100\n",
      "526/526 [==============================] - 0s 42us/step - loss: 0.3803 - acc: 0.8384\n",
      "Epoch 46/100\n",
      "526/526 [==============================] - 0s 40us/step - loss: 0.3790 - acc: 0.8346\n",
      "Epoch 47/100\n",
      "526/526 [==============================] - 0s 44us/step - loss: 0.3771 - acc: 0.8441\n",
      "Epoch 48/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.3743 - acc: 0.8365\n",
      "Epoch 49/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3717 - acc: 0.8365\n",
      "Epoch 50/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.3681 - acc: 0.8441\n",
      "Epoch 51/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3688 - acc: 0.8365\n",
      "Epoch 52/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3664 - acc: 0.8422\n",
      "Epoch 53/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.3654 - acc: 0.8403\n",
      "Epoch 54/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3631 - acc: 0.8422\n",
      "Epoch 55/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3610 - acc: 0.8441\n",
      "Epoch 56/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.3587 - acc: 0.8498\n",
      "Epoch 57/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3581 - acc: 0.8422\n",
      "Epoch 58/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3557 - acc: 0.8460\n",
      "Epoch 59/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3559 - acc: 0.8479\n",
      "Epoch 60/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3526 - acc: 0.8498\n",
      "Epoch 61/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.3521 - acc: 0.8498\n",
      "Epoch 62/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3511 - acc: 0.8574\n",
      "Epoch 63/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3498 - acc: 0.8517\n",
      "Epoch 64/100\n",
      "526/526 [==============================] - 0s 40us/step - loss: 0.3476 - acc: 0.8574\n",
      "Epoch 65/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.3472 - acc: 0.8574\n",
      "Epoch 66/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3463 - acc: 0.8555\n",
      "Epoch 67/100\n",
      "526/526 [==============================] - 0s 51us/step - loss: 0.3446 - acc: 0.8574\n",
      "Epoch 68/100\n",
      "526/526 [==============================] - 0s 46us/step - loss: 0.3431 - acc: 0.8574\n",
      "Epoch 69/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.3422 - acc: 0.8593\n",
      "Epoch 70/100\n",
      "526/526 [==============================] - 0s 40us/step - loss: 0.3417 - acc: 0.8555\n",
      "Epoch 71/100\n",
      "526/526 [==============================] - 0s 42us/step - loss: 0.3399 - acc: 0.8555\n",
      "Epoch 72/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.3389 - acc: 0.8593\n",
      "Epoch 73/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.3376 - acc: 0.8555\n",
      "Epoch 74/100\n",
      "526/526 [==============================] - 0s 40us/step - loss: 0.3366 - acc: 0.8612\n",
      "Epoch 75/100\n",
      "526/526 [==============================] - 0s 41us/step - loss: 0.3356 - acc: 0.8631\n",
      "Epoch 76/100\n",
      "526/526 [==============================] - 0s 40us/step - loss: 0.3347 - acc: 0.8593\n",
      "Epoch 77/100\n",
      "526/526 [==============================] - 0s 44us/step - loss: 0.3337 - acc: 0.8574\n",
      "Epoch 78/100\n",
      "526/526 [==============================] - 0s 38us/step - loss: 0.3330 - acc: 0.8574\n",
      "Epoch 79/100\n",
      "526/526 [==============================] - 0s 41us/step - loss: 0.3313 - acc: 0.8612\n",
      "Epoch 80/100\n",
      "526/526 [==============================] - 0s 41us/step - loss: 0.3319 - acc: 0.8612\n",
      "Epoch 81/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3301 - acc: 0.8574\n",
      "Epoch 82/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3290 - acc: 0.8555\n",
      "Epoch 83/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3279 - acc: 0.8574\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526/526 [==============================] - 0s 35us/step - loss: 0.3287 - acc: 0.8612\n",
      "Epoch 85/100\n",
      "526/526 [==============================] - 0s 34us/step - loss: 0.3267 - acc: 0.8650\n",
      "Epoch 86/100\n",
      "526/526 [==============================] - 0s 37us/step - loss: 0.3259 - acc: 0.8593\n",
      "Epoch 87/100\n",
      "526/526 [==============================] - 0s 36us/step - loss: 0.3258 - acc: 0.8574\n",
      "Epoch 88/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3235 - acc: 0.8650\n",
      "Epoch 89/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3246 - acc: 0.8593\n",
      "Epoch 90/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3221 - acc: 0.8612\n",
      "Epoch 91/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3234 - acc: 0.8593\n",
      "Epoch 92/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3202 - acc: 0.8650\n",
      "Epoch 93/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3212 - acc: 0.8593\n",
      "Epoch 94/100\n",
      "526/526 [==============================] - 0s 39us/step - loss: 0.3190 - acc: 0.8612\n",
      "Epoch 95/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3182 - acc: 0.8650\n",
      "Epoch 96/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3178 - acc: 0.8669\n",
      "Epoch 97/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3164 - acc: 0.8650\n",
      "Epoch 98/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3146 - acc: 0.8688\n",
      "Epoch 99/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3140 - acc: 0.8745\n",
      "Epoch 100/100\n",
      "526/526 [==============================] - 0s 35us/step - loss: 0.3145 - acc: 0.8669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/2_Semester/Machine Learning/MLProjects/Proposal/preprocessing.py:236: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_label[\"distance\"] = 0\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/jovyan/work/2_Semester/Machine Learning/MLProjects/Proposal/preprocessing.py:246: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_label.sort_values(by=['distance'], ascending=False, inplace=True)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "526/526 [==============================] - 0s 770us/step - loss: 0.6949 - acc: 0.5418\n",
      "Epoch 2/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.6912 - acc: 0.5494\n",
      "Epoch 3/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.6887 - acc: 0.5722\n",
      "Epoch 4/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6867 - acc: 0.5798\n",
      "Epoch 5/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.6844 - acc: 0.5913\n",
      "Epoch 6/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.6810 - acc: 0.6160\n",
      "Epoch 7/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6768 - acc: 0.6350\n",
      "Epoch 8/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.6712 - acc: 0.6692\n",
      "Epoch 9/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.6649 - acc: 0.6825\n",
      "Epoch 10/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.6579 - acc: 0.7015\n",
      "Epoch 11/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.6508 - acc: 0.6996\n",
      "Epoch 12/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.6436 - acc: 0.7281\n",
      "Epoch 13/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.6355 - acc: 0.7433\n",
      "Epoch 14/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.6262 - acc: 0.7471\n",
      "Epoch 15/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.6156 - acc: 0.7529\n",
      "Epoch 16/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.6033 - acc: 0.7624\n",
      "Epoch 17/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.5920 - acc: 0.7852\n",
      "Epoch 18/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.5792 - acc: 0.7814\n",
      "Epoch 19/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.5658 - acc: 0.7833\n",
      "Epoch 20/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.5521 - acc: 0.7871\n",
      "Epoch 21/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.5379 - acc: 0.7833\n",
      "Epoch 22/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.5241 - acc: 0.7947\n",
      "Epoch 23/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.5110 - acc: 0.7947\n",
      "Epoch 24/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4977 - acc: 0.7985\n",
      "Epoch 25/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.4870 - acc: 0.8004\n",
      "Epoch 26/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4761 - acc: 0.8061\n",
      "Epoch 27/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4672 - acc: 0.8061\n",
      "Epoch 28/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.4582 - acc: 0.8042\n",
      "Epoch 29/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4500 - acc: 0.8061\n",
      "Epoch 30/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.4438 - acc: 0.8080\n",
      "Epoch 31/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4373 - acc: 0.8137\n",
      "Epoch 32/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4313 - acc: 0.8137\n",
      "Epoch 33/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4278 - acc: 0.8156\n",
      "Epoch 34/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.4243 - acc: 0.8175\n",
      "Epoch 35/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.4198 - acc: 0.8156\n",
      "Epoch 36/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4170 - acc: 0.8156\n",
      "Epoch 37/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4136 - acc: 0.8194\n",
      "Epoch 38/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.4102 - acc: 0.8137\n",
      "Epoch 39/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4076 - acc: 0.8232\n",
      "Epoch 40/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.4058 - acc: 0.8213\n",
      "Epoch 41/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4031 - acc: 0.8251\n",
      "Epoch 42/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.4007 - acc: 0.8213\n",
      "Epoch 43/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3997 - acc: 0.8232\n",
      "Epoch 44/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3970 - acc: 0.8270\n",
      "Epoch 45/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3965 - acc: 0.8175\n",
      "Epoch 46/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3941 - acc: 0.8251\n",
      "Epoch 47/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3925 - acc: 0.8194\n",
      "Epoch 48/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3907 - acc: 0.8156\n",
      "Epoch 49/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3899 - acc: 0.8156\n",
      "Epoch 50/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3881 - acc: 0.8251\n",
      "Epoch 51/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3882 - acc: 0.8308\n",
      "Epoch 52/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3873 - acc: 0.8365\n",
      "Epoch 53/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3856 - acc: 0.8365\n",
      "Epoch 54/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3829 - acc: 0.8289\n",
      "Epoch 55/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3848 - acc: 0.8365\n",
      "Epoch 56/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3819 - acc: 0.8327\n",
      "Epoch 57/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3823 - acc: 0.8327\n",
      "Epoch 58/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3805 - acc: 0.8308\n",
      "Epoch 59/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3797 - acc: 0.8327\n",
      "Epoch 60/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3785 - acc: 0.8346\n",
      "Epoch 61/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3777 - acc: 0.8327\n",
      "Epoch 62/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3779 - acc: 0.8346\n",
      "Epoch 63/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3778 - acc: 0.8422\n",
      "Epoch 64/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3770 - acc: 0.8327\n",
      "Epoch 65/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3766 - acc: 0.8365\n",
      "Epoch 66/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3732 - acc: 0.8403\n",
      "Epoch 67/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3752 - acc: 0.8384\n",
      "Epoch 68/100\n",
      "526/526 [==============================] - 0s 32us/step - loss: 0.3737 - acc: 0.8403\n",
      "Epoch 69/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3743 - acc: 0.8460\n",
      "Epoch 70/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3704 - acc: 0.8460\n",
      "Epoch 71/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3711 - acc: 0.8384\n",
      "Epoch 72/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3705 - acc: 0.8384\n",
      "Epoch 73/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3714 - acc: 0.8479\n",
      "Epoch 74/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3710 - acc: 0.8441\n",
      "Epoch 75/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3692 - acc: 0.8422\n",
      "Epoch 76/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3696 - acc: 0.8479\n",
      "Epoch 77/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3683 - acc: 0.8422\n",
      "Epoch 78/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3664 - acc: 0.8384\n",
      "Epoch 79/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3671 - acc: 0.8346\n",
      "Epoch 80/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3668 - acc: 0.8403\n",
      "Epoch 81/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3662 - acc: 0.8460\n",
      "Epoch 82/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3652 - acc: 0.8479\n",
      "Epoch 83/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3648 - acc: 0.8460\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526/526 [==============================] - 0s 32us/step - loss: 0.3635 - acc: 0.8517\n",
      "Epoch 85/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3634 - acc: 0.8403\n",
      "Epoch 86/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3629 - acc: 0.8479\n",
      "Epoch 87/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3634 - acc: 0.8479\n",
      "Epoch 88/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3619 - acc: 0.8479\n",
      "Epoch 89/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3631 - acc: 0.8460\n",
      "Epoch 90/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3608 - acc: 0.8498\n",
      "Epoch 91/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3601 - acc: 0.8422\n",
      "Epoch 92/100\n",
      "526/526 [==============================] - 0s 30us/step - loss: 0.3610 - acc: 0.8460\n",
      "Epoch 93/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3596 - acc: 0.8460\n",
      "Epoch 94/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3589 - acc: 0.8479\n",
      "Epoch 95/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3598 - acc: 0.8498\n",
      "Epoch 96/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3591 - acc: 0.8479\n",
      "Epoch 97/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3591 - acc: 0.8479\n",
      "Epoch 98/100\n",
      "526/526 [==============================] - 0s 28us/step - loss: 0.3571 - acc: 0.8498\n",
      "Epoch 99/100\n",
      "526/526 [==============================] - 0s 29us/step - loss: 0.3567 - acc: 0.8517\n",
      "Epoch 100/100\n",
      "526/526 [==============================] - 0s 31us/step - loss: 0.3577 - acc: 0.8536\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sum_profit_share = 0\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    #%%capture\n",
    "    # transform the df to X_f using the exact ratio of 0 and 1: 17%\n",
    "    X_f = preprocessing.centroid_undersampling(X=df, f=0.17)\n",
    "\n",
    "    # now the dataset is balanced\n",
    "    #countplot(x=\"Response\", data=X_f)\n",
    "\n",
    "    # perform the train, test split\n",
    "    X_train, X_test, y_train, y_test = utils.data_split(X_f, test_size=0.2, random_state=i)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(6, activation=\"relu\", input_dim=30))\n",
    "    model.add(layers.Dense(6, activation=\"relu\"))\n",
    "    model.add(layers.Dense(6, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=100)\n",
    "    y_predicted = model.predict(X_test)\n",
    "\n",
    "    y_pred = []\n",
    "    for i in y_predicted:\n",
    "        if i < 0.5:\n",
    "            i=0\n",
    "            y_pred.append(i)\n",
    "        else:\n",
    "            i=1\n",
    "            y_pred.append(i)\n",
    "            \n",
    "    x = utils.profit_share(y_pred, y_test)\n",
    "    sum_profit_share = sum_profit_share + x\n",
    "\n",
    "average_profit_share = (sum_profit_share/len(range(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.736"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_profit_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
