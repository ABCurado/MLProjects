{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the files to be shared among all notebooks \n",
    "import utils\n",
    "import preprocessing\n",
    "import data_visualization\n",
    "import feature_engineering\n",
    "from ML_algorithms import *\n",
    "import pandas as pd\n",
    "from seaborn import countplot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing.encode_education(df)\n",
    "df = preprocessing.one_hot_encoding(df,columns = [\"Marital_Status\"])\n",
    "df = preprocessing.encode_days_as_costumer(df)\n",
    "df = feature_engineering.drop_useless_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing.impute_income_KNN(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Kidhome\",\"Teenhome\", \"Education\",\"Year_Birth\",\"Dt_Customer\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the train, test split\n",
    "X_train, X_test, y_train, y_test = utils.data_split(df, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = preprocessing.Min_Max_Train(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a list of available initializations:\n",
    "    \n",
    "    * uniform\n",
    "    * lecun_uniform: Uniform initialization scaled by the square root of the number of inputs (LeCun 98).\n",
    "    normal\n",
    "    * identity: Use with square 2D layers (shape[0] == shape[1]).\n",
    "    * orthogonal: Use with square 2D layers (shape[0] == shape[1]).\n",
    "    * zero\n",
    "    * one\n",
    "    * glorot_normal: Gaussian initialization scaled by fan_in + fan_out (Glorot 2010)\n",
    "    * glorot_uniform\n",
    "    * he_normal: Gaussian initialization scaled by fan_in (He et al., 2014)\n",
    "    * he_uniform\n",
    "    \n",
    "####  a list of available optimizers:\n",
    "\n",
    "    * adam\n",
    "    * sgd\n",
    "    * adagrad\n",
    "    * adadelta\n",
    "    * nadam\n",
    "    * rmsprop\n",
    "    * adamax\n",
    "    \n",
    "#### a list of available loss functions:\n",
    "\n",
    "    * binary_crossentropy\n",
    "    * mean_squared_error\n",
    "    * categorical_hinge\n",
    "    * kld\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = KerasNN(X_train, X_test, y_train, y_test, input_dim=27,init=\"uniform\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initializations_list = [\"uniform\",\"lecun_uniform\",\"zero\",\"one\",\"glorot_normal\",\"glorot_uniform\",\"he_normal\",\"he_uniform\"]\n",
    "optimizers_list = [\"adam\",\"rmsprop\"]\n",
    "loss_list = [\"binary_crossentropy\",\"mean_squared_error\"]\n",
    "seeds = [0,1,2,3,4]\n",
    "\n",
    "for i in  initializations_list:\n",
    "    for j in optimizers_list:\n",
    "        for n in loss_list:\n",
    "            for z in seeds:\n",
    "                model = KerasNN(X_train, X_test, y_train, y_test, input_dim=27,optimizer=j,loss=n,init=i,random_state=z)\n",
    "                print(\"The initialization used is:\", i)\n",
    "                print(\"The optimizer used is:\", j)\n",
    "                print(\"The loss used is:\", n)\n",
    "                print(\"Seed:\", z)\n",
    "                print(\"-----------------------------------------------------\")\n",
    "                #utils.NN_evaluation(model, X_test, y_test)\n",
    "\n",
    "                output_list = [i,j,n,utils.NN_evaluation(model, X_test, y_test)]\n",
    "                output = open(\"Keras_Neural_Net_Results.txt\", \"a\")\n",
    "                output.write(str(output_list))\n",
    "                output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling on NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn import over_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = over_sampling.RandomOverSampler(random_state=seed, ratio=0.5)\n",
    "resamp_x, resamp_y= ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling_model = KerasNN(resamp_x, X_test, resamp_y, y_test, input_dim=30,init=\"he_normal\")\n",
    "\n",
    "utils.NN_evaluation(oversampling_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = over_sampling.ADASYN(random_state=seed, ratio=0.7)\n",
    "resamp_x, resamp_y= ada.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling_model = KerasNN(resamp_x, X_test, resamp_y, y_test, input_dim=30,init=\"he_normal\")\n",
    "\n",
    "utils.NN_evaluation(oversampling_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smo = over_sampling.SMOTE(random_state=seed, ratio=0.5)\n",
    "resamp_x, resamp_y= smo.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling_model = KerasNN(resamp_x, X_test, resamp_y, y_test, input_dim=30,init=\"he_normal\")\n",
    "\n",
    "utils.NN_evaluation(oversampling_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling on NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn import under_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = under_sampling.RandomUnderSampler(random_state=seed)\n",
    "resamp_x, resamp_y= rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling_model = KerasNN(resamp_x, X_test, resamp_y, y_test, input_dim=30,init=\"he_normal\")\n",
    "\n",
    "utils.NN_evaluation(oversampling_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tom = under_sampling.TomekLinks(random_state=seed)\n",
    "resamp_x, resamp_y= tom.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling_model = KerasNN(resamp_x, X_test, resamp_y, y_test, input_dim=30,init=\"he_normal\")\n",
    "\n",
    "utils.NN_evaluation(oversampling_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aknn = under_sampling.AllKNN(random_state=seed, n_neighbors=5)\n",
    "resamp_x, resamp_y= aknn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling_model = KerasNN(resamp_x, X_test, resamp_y, y_test, input_dim=30,init=\"he_normal\")\n",
    "\n",
    "utils.NN_evaluation(oversampling_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enn = under_sampling.EditedNearestNeighbours(random_state=seed, n_neighbors=3)\n",
    "resamp_x, resamp_y= enn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling_model = KerasNN(resamp_x, X_test, resamp_y, y_test, input_dim=30,init=\"he_normal\")\n",
    "\n",
    "utils.NN_evaluation(oversampling_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn import combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smotom = combine.SMOTETomek(random_state=seed, ratio=0.8)\n",
    "resamp_x, resamp_y= smotom.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling_model = KerasNN(resamp_x, X_test, resamp_y, y_test, input_dim=30,init=\"he_normal\")\n",
    "\n",
    "utils.NN_evaluation(oversampling_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smotenn = combine.SMOTEENN(random_state=seed, ratio=0.8)\n",
    "resamp_x, resamp_y= smotenn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling_model = KerasNN(resamp_x, X_test, resamp_y, y_test, input_dim=30,init=\"he_normal\")\n",
    "\n",
    "utils.NN_evaluation(oversampling_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_NB(X_train, X_test, y_train, y_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    # Only fit the training data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, y_train)\n",
    "    y_pred = gnb.predict(X_test)\n",
    "    \n",
    "    print(\"Accuracy {:1.2f}\".format(utils.calculate_accuracy(y_pred, y_test)))\n",
    "    print(\"Area under the curve {:1.2f}\".format(utils.calculate_auc(y_pred, y_test)))\n",
    "    print(\"Precision {:1.2f}\".format(utils.calculate_precision_score(y_pred, y_test)))\n",
    "    print(\"Recall {:1.2f}\".format(utils.calculate_recall_score(y_pred, y_test)))\n",
    "    print(\"Profit Share {:1.2f}\".format(utils.profit_share(y_pred, y_test)))\n",
    "    return utils.profit_share(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Multinomial_NB(X_train, X_test, y_train, y_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    # Only fit the training data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X_train, y_train)\n",
    "    y_pred = mnb.predict(X_test)\n",
    "    return utils.profit_share(y_pred, y_test)\n",
    "    return mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Complement_NB(X_train, X_test, y_train, y_test):\n",
    "    cnb = ComplementNB()\n",
    "    cnb.\n",
    "    cnb.fit(X_train, y_train)\n",
    "    y_pred = cnb.predict(X_test)\n",
    "    return utils.profit_share(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bernoulli_NB(X_train, X_test, y_train, y_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    # Only fit the training data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(X_train, y_train)\n",
    "    y_pred = bnb.predict(X_test)\n",
    "    return utils.profit_share(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KerasNN(X_train, X_test, y_train, y_test, input_dim=32, n_layers=4, optimizer=\"rmsprop\", loss=\"binary_crossentropy\", init=\"uniform\", metrics=[\"accuracy\"], random_state=42):\n",
    "    \"\"\"\n",
    "    Keras Neural Network, define the amount of layers you want, which optimizer you want to use and which loss function you want to apply.\n",
    "    \"\"\" \n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(6, activation=\"relu\", input_dim=input_dim))\n",
    "    for num in range(n_layers-2):\n",
    "        model.add(layers.Dense(6, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\", init=init))\n",
    "    model.compile(optimizer, loss, metrics=metrics)\n",
    "    \n",
    "    initial_weights = model.get_weights()\n",
    "    \n",
    "    utils.shuffle_weights(model, initial_weights)\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
